<system>
  <log>
    format json
    time_format %Y-%m-%dT%H:%M:%S%z
  </log>
</system>

<source>
  @type systemd
  path /var/log/journal
  tag journal
  <entry>
    fields_strip_underscores true
    fields_lowercase true
  </entry>
</source>
# system-fluentd config
# drop fluentd logs
<match fluent.**>
  @type null
</match>

# read logs from k8s containers
<source>
  @type tail
  path /var/log/containers/*.log
  read_from_head true
  pos_file /var/log/fluentd-container-log.pos
  time_format %Y-%m-%dT%H:%M:%S
  tag kubernetes.*
  format json
</source>


# if you want to enable ssl of prometheus uncomment following line. And add corresponding match. Do not change the path of certificates.
<source>
  @type prometheus
  ##uncomment below line "bind" in IPv6 Env
  #bind ::
#  <ssl>
#   enable true
#   certificate_path "/etc/fluent/certs/prometheus-crt.pem"
#   private_key_path "/etc/fluent/certs/prometheus-key.pem"
#   ca_path "/etc/fluent/certs/prometheus-root-ca.pem"
#  </ssl>
</source>

<source>
  @type monitor_agent
</source>

<source>
  @type forward
</source>

# input plugin that collects metrics from MonitorAgent
<source>
 @type prometheus_monitor
  <labels>
    host ${hostname}
  </labels>
</source>

# input plugin that collects metrics for output plugin
<source>
  @type prometheus_output_monitor
  <labels>
    host ${hostname}
  </labels>
</source>

# input plugin that collects metrics for in_tail plugin
<source>
  @type prometheus_tail_monitor
  <labels>
    host ${hostname}
  </labels>
</source>

# parse logs using kubernetes_metadata filter
<filter kubernetes.**>
  @type kubernetes_metadata
  ##Setting kubernetes_url with service name since URL encoding does not work correctly with IPv6 addresses
  # The format is https://<kubernetes-service-name>.<namespace>.svc:<kubernetes-service-port>
  kubernetes_url https://kubernetes.default.svc:443
</filter>

#dedot kubernetes labels to avoid mapper parsing exception during processing of logs having '.' in field names, this was taken care by kubernetes metadata filter till 22.09FP2 release.
<filter kubernetes.**>
  @type record_modifier
  <record>
    _dummy_ ${if m=record.dig("kubernetes","labels");record["kubernetes"]["labels"]={}.tap{|n|m.each{|k,v|n[k.gsub(/[.]/,'_')]=v}};end}
  </record>
    remove_keys _dummy_
</filter>

# rewrite_tag_filter does not support nested fields like
# kubernetes.container_name, so this exists to flatten the fields
# and use them in rewrite_tag_filter
<filter kubernetes.**>
  @type record_transformer
  enable_ruby true
  <record>
    pod-name ${record["kubernetes"]["pod_name"]}
    namespace ${record["kubernetes"]["namespace_name"]}
    tenant_msgtype ${record["kubernetes"]["namespace_name"]}.${record["type"]}
  </record>
</filter>

# retag based on the container name of the log message
<match kubernetes.**>
  @type rewrite_tag_filter
  <rule>
    key tenant_msgtype
    pattern ^(.+)$
    tag nokia.logging.$1
  </rule>
</match>

# remove the unnecessary field as the information is already available on other fields.
<filter nokia.logging.**>
  @type record_transformer
  remove_keys tenant_msgtype
</filter>

# do not forward kube-system logs as k8s generates a lot of logs
<match nokia.logging.kube-system.**>
  @type null
</match>

# forward all tenants logs to public indexsearch
# do not split per type now as standard k8s logs do not have type
<match nokia.logging.**>
  @type opensearch
  @log_level info
  include_tag_key true
  #Default name of the indexsearch service is indexsearch, so the default value of host is indexsearch in fluentd config.
  #If the certificate for indexsearch is generated with CN=<service-name>.<namespace> , update the host field in the fluentd configuration accordingly
  host indexsearch
  port 9200
  #Below commented lines are ssl properties. Please uncomment below commented lines from user to ca_file when you want to use.
  #When security is enabled for opensearch, provide details of the user (having all_access role) for authentication to opensearch. The user's credentials must be added in pre-created secret and the details of the secret keys must be updated in the config.
  #Note: secretData's key must match to parameter set in this config enclosed in double angular brackets << >>.
  ##Example: user <<indexsearch_username>>, password <<indexsearch_password>>, ca_file <<isroot_cert>>
  #When istio is enabled, only username, password and scheme are required. Set ssl_verify as false and other SSL properties are not required.
  #user <<indexsearch_username>>
  #password <<indexsearch_password>>
  #scheme https
  #ssl_verify true
  #ssl_version TLSv1_2
  ##use the same certificate name configured in values.yaml.
  #ca_file <<isroot_cert>>
  logstash_format true
  logstash_prefix log-${tag[2]}
  reload_connections false
  reconnect_on_error true
  reload_on_failure true
  request_timeout 10s
  <buffer>
    @type file
    chunk_limit_size 8MB
    path /var/log/fluent/is-fluentd-buffer/nokia.logging.all
    total_limit_size 1024m
  </buffer>
</match>

# sending all journal logs to indexsearch.
<match journal.**>
  @type opensearch
  @log_level info
  include_tag_key true
  #Default name of the indexsearch service is indexsearch, so the default value of host is indexsearch in fluentd config.
  #If the certificate for indexsearch is generated with CN=<service-name>.<namespace> , update the host field in the fluentd configuration accordingly
  host indexsearch
  port 9200
  #Below commented lines are ssl properties. Please uncomment below commented lines from user to ca_file when you want to use.
  #When security is enabled for opensearch, provide details of the user (having all_access role) for authentication to opensearch. The user's credentials must be added in pre-created secret and the details of the secret keys must be updated in the config.
  #Note: secretData's key must match to parameter set in this config enclosed in double angular brackets << >>.
  ##Example: user <<indexsearch_username>>, password <<indexsearch_password>>, ca_file <<isroot_cert>>
  #When istio is enabled, only username, password and scheme are required. Set ssl_verify as false and other SSL properties are not required.
  #user <<indexsearch_username>>
  #password <<indexsearch_password>> 
  #scheme https
  #ssl_verify true
  #ssl_version TLSv1_2
  ##use the same certificate name configured in values.yaml.
  #ca_file <<isroot_cert>>
  logstash_format true
  logstash_prefix journal
  reload_connections false
  reconnect_on_error true
  reload_on_failure true
  request_timeout 10s
  <buffer>
    @type file
    chunk_limit_size 8MB
    path /var/log/fluent/is-fluentd-buffer/journal.all
    total_limit_size 1024m
  </buffer>
</match>
